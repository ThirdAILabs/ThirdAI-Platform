{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "import time\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "BASE_URL = \"http://34.236.171.80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signup(username: str, email: str, password: str):\n",
    "    \"\"\"\n",
    "    Signup a user with the given username, email, and password.\n",
    "    Once the request is sent, the user will receive an email with a link to verify their account.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/api/user/email-signup-basic\"\n",
    "    payload = {\"username\": username, \"email\": email, \"password\": password}\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def login(email: str, password: str):\n",
    "    \"\"\"\n",
    "    Login a user with the given email and password.\n",
    "    If successful, this function returns an access token.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/api/user/email-login\"\n",
    "    response = requests.get(url, auth=HTTPBasicAuth(email, password))\n",
    "    result = response.json()\n",
    "    token = result.get(\"data\", {}).get(\"access_token\")\n",
    "    return token\n",
    "\n",
    "def list_models(\n",
    "    name: str, token: str, domain=None, username=None, type=None, sub_type=None, access_level=None\n",
    "):\n",
    "    \"\"\"\n",
    "    List models based on filters for authenticated users.\n",
    "    Returns:\n",
    "    - List of models that match the provided filters.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/api/model/list\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\n",
    "        \"name\": name,\n",
    "        \"domain\": domain,\n",
    "        \"username\": username,\n",
    "        \"type\": type,\n",
    "        \"sub_type\": sub_type,\n",
    "        \"access_level\": access_level,\n",
    "    }\n",
    "    response = requests.get(\n",
    "        url, headers=headers, params={k: v for k, v in params.items() if v is not None}\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model(model_identifier: str, token: str):\n",
    "    \"\"\"\n",
    "    Delete a specified model. model_identifier is username/modelname\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/api/model/delete\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"model_identifier\": model_identifier}\n",
    "    response = requests.post(url, headers=headers, params=params)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever_model(\n",
    "    model_name: str,\n",
    "    token: str,\n",
    "    base_model_identifier: Optional[str] = None,\n",
    "    files: Optional[List[str]] = None,  # Local file paths\n",
    "    s3_urls: Optional[List[str]] = None,  # S3 URLs\n",
    "    nfs_paths: Optional[List[str]] = None,  # NFS paths\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates and trains an NDB retriever model with local, S3, and NFS files.\n",
    "    Parameters:\n",
    "    - model_name: The name of the model.\n",
    "    - token: Authorization token from login.\n",
    "    - base_model_identifier: (Optional) The identifier of the base model to use.\n",
    "    - files: (Optional) List of local file paths.\n",
    "    - s3_urls: (Optional) List of S3 URLs for files.\n",
    "    - nfs_paths: (Optional) List of NFS paths for files.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/api/train/ndb\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    # Construct file information based on the different sources\n",
    "    file_info = {\"unsupervised_files\": [], \"supervised_files\": [], \"test_files\": []}\n",
    "    if files:\n",
    "        for file_path in files:\n",
    "            file_info[\"unsupervised_files\"].append(\n",
    "                {\"path\": file_path, \"location\": \"local\"}\n",
    "            )\n",
    "    if s3_urls:\n",
    "        for s3_url in s3_urls:\n",
    "            file_info[\"unsupervised_files\"].append({\"path\": s3_url, \"location\": \"s3\"})\n",
    "    if nfs_paths:\n",
    "        for nfs_path in nfs_paths:\n",
    "            file_info[\"unsupervised_files\"].append(\n",
    "                {\"path\": nfs_path, \"location\": \"nfs\"}\n",
    "            )\n",
    "    # Prepare the files for upload\n",
    "    upload_files = []\n",
    "    if files:\n",
    "        for file_path in files:\n",
    "            if os.path.isfile(file_path):\n",
    "                upload_files.append((\"files\", open(file_path, \"rb\")))\n",
    "    print(upload_files)\n",
    "    upload_files.append(\n",
    "        (\"file_info\", (None, json.dumps(file_info), \"application/json\"))\n",
    "    )\n",
    "    print(upload_files)\n",
    "    try:\n",
    "        # Send the POST request to the /ndb endpoint\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            params={\n",
    "                \"model_name\": model_name,\n",
    "                \"base_model_identifier\": base_model_identifier,\n",
    "            },\n",
    "            files=upload_files,\n",
    "        )\n",
    "        # Check for the response\n",
    "        if response.status_code == 200:\n",
    "            print(\"Model training job submitted successfully.\")\n",
    "            print(response.json())\n",
    "            return response.json()[\"data\"][\"model_id\"]\n",
    "        else:\n",
    "            print(\"Failed to submit the model training job.\")\n",
    "            print(response.json())\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def await_train(model_identifier: str, token: str):\n",
    "    \"\"\"\n",
    "    Blocks until the model has finished training.\n",
    "    Parameters:\n",
    "    - model_identifier: <username>/<modelname>\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for checking training status\n",
    "    status_url = f\"{BASE_URL}/api/train/status\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    while True:\n",
    "        # Make a GET request to check the training status\n",
    "        response = requests.get(\n",
    "            status_url, params={\"model_identifier\": model_identifier}, headers=headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to get training status: {response.status_code}, {response.text}\"\n",
    "            )\n",
    "        # Check the training status\n",
    "        status = response.json()[\"data\"][\"train_status\"]\n",
    "        if status == \"complete\":\n",
    "            print(\"Training completed successfully.\")\n",
    "            break\n",
    "        elif status == \"failed\":\n",
    "            raise Exception(\"Training failed.\")\n",
    "        print(\"Training in progress...\")\n",
    "        time.sleep(10)  # Wait for 10 seconds before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_retrieval_model_documents(model_id: str, local_files: List[str], token: str):\n",
    "    \"\"\"\n",
    "    Inserts documents into an existing retrieval model.\n",
    "    Parameters:\n",
    "    - model_id: model ID as returned by create_retrieval_model. You can also find the model ID in the list returned by list_models.\n",
    "    - local_files: List of local file paths.\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    query_url = f\"{BASE_URL}/{model_id}/insert\"\n",
    "    files = [(\"files\", open(local_file, \"rb\")) for local_file in local_files]\n",
    "    documents = [create_doc_dict(local_file, \"local\") for local_file in local_files]\n",
    "    files.append((\"documents\", (None, json.dumps(documents), \"application/json\")))\n",
    "    response = requests.post(\n",
    "        query_url,\n",
    "        files=files,\n",
    "        headers=headers,\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def create_doc_dict(path: str, doc_type: str):\n",
    "    \"\"\"\n",
    "    Creates a document dictionary for different document types.\n",
    "    Parameters:\n",
    "    path (str): Path to the document file.\n",
    "    doc_type (str): Type of the document location.\n",
    "    Returns:\n",
    "    dict[str, str]: Dictionary containing document details.\n",
    "    Raises:\n",
    "    Exception: If the document type is not supported.\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(path)\n",
    "    if ext == \".pdf\":\n",
    "        return {\"document_type\": \"PDF\", \"path\": path, \"location\": doc_type}\n",
    "    if ext == \".csv\":\n",
    "        return {\"document_type\": \"CSV\", \"path\": path, \"location\": doc_type}\n",
    "    if ext == \".docx\":\n",
    "        return {\"document_type\": \"DOCX\", \"path\": path, \"location\": doc_type}\n",
    "    raise Exception(f\"Please add a map from {ext} to document dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_token_classifier(model_name: str, task_prompt: str, tags: List[dict], token: str, num_sentences: int = 10_000, num_samples_per_tag: Optional[int] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Trains a token classification model that can detect the provided tags.\n",
    "    It first generates training samples which contain tokens similar to the provided tag examples, then trains a model with this data.\n",
    "    Parameters:\n",
    "    - model_name: The name of the new model.\n",
    "    - task_prompt: A prompt for the task that the model will perform, e.g. \"Detect PII\"\n",
    "    - tags: A list of classes that tokens can be tagged with, accompanied by a description and examples, e.g.\n",
    "        [\n",
    "            {\"name\": \"NAME\", \"examples\": [\"John Smith\", \"Anshumali Shrivastava\"], \"description\": \"A person's name\"},\n",
    "            {\"name\": \"PHONE_NUMBER\", \"examples\": [\"123-123-1234\", \"123 123 1234\", \"(123)-123-1234\"], \"description\": \"American phone number\"},\n",
    "        ]\n",
    "    - num_samples: The number of samples that will be generated for model training.\n",
    "    - token: Authorization token from login.\n",
    "    \"\"\"\n",
    "    if num_samples_per_tag is None:\n",
    "        num_samples_per_tag = max((num_sentences // len(tags)), 50)\n",
    "    # Set up the headers with authorization\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "    # Prepare the form data\n",
    "    form_data = {\n",
    "        'datagen_options': json.dumps({\n",
    "            'task_prompt': task_prompt,\n",
    "            'datagen_options': {\n",
    "                'sub_type': 'token',\n",
    "                'task_prompt': task_prompt, # This can also be a distinct prompt about the domain of the task.\n",
    "                'tags': tags,\n",
    "                'num_sentences_to_generate': num_sentences,\n",
    "                'num_samples_per_tag': num_samples_per_tag,\n",
    "            }\n",
    "        })\n",
    "    }\n",
    "    # Make the POST request\n",
    "    response = requests.post(\n",
    "        f'{BASE_URL}/api/train/nlp-datagen?model_name={model_name}',\n",
    "        data=form_data,\n",
    "        headers=headers\n",
    "    )\n",
    "    print(response.content)\n",
    "    # Check for success\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def await_train(model_identifier: str, token: str):\n",
    "    \"\"\"\n",
    "    Blocks until the model has finished training.\n",
    "    Parameters:\n",
    "    - model_identifier: <username>/<modelname>\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for checking training status\n",
    "    status_url = f\"{BASE_URL}/api/train/status\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    while True:\n",
    "        # Make a GET request to check the training status\n",
    "        response = requests.get(\n",
    "            status_url, params={\"model_identifier\": model_identifier}, headers=headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to get training status: {response.status_code}, {response.text}\"\n",
    "            )\n",
    "        # Check the training status\n",
    "        status = response.json()[\"data\"][\"train_status\"]\n",
    "        if status == \"complete\":\n",
    "            print(\"Training completed successfully.\")\n",
    "            break\n",
    "        elif status == \"failed\":\n",
    "            raise Exception(\"Training failed.\")\n",
    "        print(\"Training in progress...\")\n",
    "        time.sleep(10)  # Wait for 10 seconds before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(model_identifier: str, token: str):\n",
    "    \"\"\"\n",
    "    Allocates resources to serve the model.\n",
    "    Parameters:\n",
    "    - model_identifier: <username>/<modelname>\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for model deployment\n",
    "    deploy_url = f\"{BASE_URL}/api/deploy/run\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"model_identifier\": model_identifier}\n",
    "    # Make a POST request to deploy the model\n",
    "    response = requests.post(deploy_url, headers=headers, params=params)\n",
    "    # Extract deployment ID from the response\n",
    "    content = response.json()\n",
    "    deployment_id = content[\"data\"][\"model_id\"]\n",
    "    print(f\"Model deployed successfully. Deployment ID: {deployment_id}\")\n",
    "    return deployment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def await_deploy(model_identifier: str, token: str):\n",
    "    \"\"\"\n",
    "    Blocks until the model is deployed.\n",
    "    Parameters:\n",
    "    - model_identifier: <username>/<modelname>\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for checking deployment status\n",
    "    status_url = f\"{BASE_URL}/api/deploy/status\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    while True:\n",
    "        # Make a GET request to check the deployment status\n",
    "        response = requests.get(\n",
    "            status_url, params={\"model_identifier\": model_identifier}, headers=headers\n",
    "        )\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to get deployment status: {response.status_code}, {response.text}\"\n",
    "            )\n",
    "        # Check the deployment status\n",
    "        status = response.json()[\"data\"][\"deploy_status\"]\n",
    "        if status == \"complete\":\n",
    "            print(\"Deployment completed successfully.\")\n",
    "            break\n",
    "        elif status == \"failed\":\n",
    "            raise Exception(\"Deployment failed.\")\n",
    "        print(\"Deployment in progress...\")\n",
    "        time.sleep(10)  # Wait for 10 seconds before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_retrieval_model(model_id: str, query: str, token: str):\n",
    "    \"\"\"\n",
    "    Retrieves top k most relevant references to the query from the deployed model.\n",
    "    Parameters:\n",
    "    - model_id: <username>/<modelname>\n",
    "    - query: The query to search for.\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for querying the deployed model\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    query_url = f\"{BASE_URL}/{model_id}/search\"\n",
    "    # Set up the query parameters\n",
    "    base_params = {\"query\": query, \"top_k\": 5}\n",
    "    # Make a POST request to query the model\n",
    "    response = requests.post(\n",
    "        query_url,\n",
    "        json=base_params,\n",
    "        headers=headers,\n",
    "    )\n",
    "    # Check if the query was successful; if not, raise an exception\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Query failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()[\"data\"][\"references\"]\n",
    "\n",
    "def query_sentiment_model(model_id: str, query: str, token: str):\n",
    "    \"\"\"\n",
    "    Retrieves top k most relevant references to the query from the deployed model.\n",
    "    Parameters:\n",
    "    - model_id: <username>/<modelname>\n",
    "    - query: The query to search for.\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    # Define the URL for querying the deployed model\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    query_url = f\"{BASE_URL}/{model_id}/predict\"\n",
    "    # Set up the query parameters\n",
    "    base_params = {\"text\": query, \"top_k\": 5}\n",
    "    # Make a POST request to query the model\n",
    "    response = requests.post(\n",
    "        query_url,\n",
    "        json=base_params,\n",
    "        headers=headers,\n",
    "    )\n",
    "    # Check if the query was successful; if not, raise an exception\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Query failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()[\"data\"][\"predicted_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upvote_reference(model_id: str, query: str, reference_id: str, token: str):\n",
    "    \"\"\"\n",
    "    Upvotes a reference for a given query.\n",
    "    Parameters:\n",
    "    - model_id: model ID as returned by create_retrieval_model. You can also find the model ID in the list returned by list_models.\n",
    "    - query: The query for which the reference is upvoted.\n",
    "    - reference_id: The ID of the reference to upvote.\n",
    "    - token: Authorization token from login\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    query_url = f\"{BASE_URL}/{model_id}/upvote\"\n",
    "    # Set up the query parameters\n",
    "    text_id_pairs = [{\"query_text\": query, \"reference_id\": reference_id}]\n",
    "    # Make a POST request to query the model\n",
    "    response = requests.post(\n",
    "        query_url,\n",
    "        json={\"text_id_pairs\": text_id_pairs},\n",
    "        headers=headers,\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_classifier_predict(model_id: str, query: str, token: str, top_k=1):\n",
    "    \"\"\"\n",
    "    Predicts the NER tags for a given query.\n",
    "    Parameters:\n",
    "    - model_id: model ID as returned by create_token_classifier. You can also find the model ID in the list returned by list_models.\n",
    "    - query: The passage to predict the NER tags for.\n",
    "    - token: Authorization token from login\n",
    "    - top_k: The number of tags predicted for each token.\n",
    "    Returns a dictionary in this format:\n",
    "    {\n",
    "        \"text\": \"The text that was passed in\",\n",
    "        \"predicted_tags\": [\n",
    "            [\"TOP_TAG_FOR_FIRST_TOKEN\", \"SCORE_FOR_TOP_TAG_FOR_FIRST_TOKEN\", ...],\n",
    "            [\"TOP_TAG_FOR_SECOND_TOKEN\", \"SCORE_FOR_TOP_TAG_FOR_SECOND_TOKEN\", ...],\n",
    "            ...\n",
    "            [\"TOP_TAG_FOR_LAST_TOKEN\", \"SCORE_FOR_TOP_TAG_FOR_LAST_TOKEN\", ...]\n",
    "        ]\n",
    "    }\n",
    "    The number of tags predicted for each token is specified in the top_k parameter.\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    query_url = f\"{BASE_URL}/{model_id}/predict\"\n",
    "    base_params = {\"text\": query, \"top_k\": top_k}\n",
    "    response = requests.post(\n",
    "        query_url,\n",
    "        json=base_params,\n",
    "        headers=headers,\n",
    "    )\n",
    "    # Check if the query was successful; if not, raise an exception\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Query failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()[\"data\"]\n",
    "\n",
    "def obfuscate_pii(token_classifier_model_id: str, text_chunks: List[str], auth_token: str):\n",
    "    \"\"\"\n",
    "    Obfuscates PII in the references using the NER model by replacing them with placeholders.\n",
    "    Parameters:\n",
    "    - token_classifier_model_id: model ID as returned by create_token_classifier. You can also find the model ID in the list returned by list_models.\n",
    "    - text_chunks: A list of strings containing the text to obfuscate.\n",
    "    - auth_token: Authorization token from login\n",
    "    Returns a tuple containing:\n",
    "    - A list of strings containing the obfuscated PII information.\n",
    "    - A dictionary containing the mapping of obfuscated tokens to original tokens.\n",
    "    \"\"\"\n",
    "    token_to_tag = {}\n",
    "    token_counts = {}\n",
    "    for text in text_chunks:\n",
    "        text = \" \".join(text.split())\n",
    "        predicted_tags = token_classifier_predict(auth_token, token_classifier_model_id, text)\n",
    "        predicted_tags = predicted_tags[\"predicted_tags\"]\n",
    "        for i, token in enumerate(text.split()):\n",
    "            tag = predicted_tags[i][0]\n",
    "            if tag != \"O\":\n",
    "                if token not in token_to_tag:\n",
    "                    tg = f\"<{tag}>\"\n",
    "                    token_to_tag[token] = tg\n",
    "    token_counts = {v: 0 for k, v in token_to_tag.items()}\n",
    "    inverse_map = {}\n",
    "    for k, v in token_to_tag.items():\n",
    "        new_tag = v[:-1] + f\"_{token_counts[v]}>\"\n",
    "        inverse_map[new_tag] = k\n",
    "        token_to_tag[k] = new_tag\n",
    "        token_counts[v] += 1\n",
    "    output_text = []\n",
    "    for text in text_chunks:\n",
    "        text = \" \".join(text.split())\n",
    "        redacted_text = [\n",
    "            word if word not in token_to_tag else token_to_tag[word]\n",
    "            for word in text.split()\n",
    "        ]\n",
    "        output_text.append(\" \".join(redacted_text))\n",
    "    return output_text, inverse_map\n",
    "\n",
    "def restore_pii(text: str, tag_to_token: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Restores the PII in the text by replacing the placeholders with the original tokens.\n",
    "    Parameters:\n",
    "    - text: A string containing the obfuscated PII information.\n",
    "    - tag_to_token: A dictionary containing the mapping of obfuscated tokens to original tokens.\n",
    "\n",
    "    Returns a string containing the restored PII information.\n",
    "    \"\"\"\n",
    "    restored_text = []\n",
    "    for word in text.split():\n",
    "        word = strip_non_alphanumeric(word)\n",
    "        if word in tag_to_token.keys():\n",
    "            restored_text.append(tag_to_token[word])\n",
    "        else:\n",
    "            restored_text.append(word)\n",
    "    return \" \".join(restored_text)\n",
    "\n",
    "\n",
    "def strip_non_alphanumeric(word):\n",
    "    pattern = r\"^[^a-zA-Z0-9_<>\\s]+|[^a-zA-Z0-9_<>\\s]+$\"\n",
    "    cleaned_string = re.sub(pattern, \"\", word)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model_id: str, user_input: str, token: str, session_id: str = None):\n",
    "    \"\"\"\n",
    "    Sends a chat request to the /chat endpoint.\n",
    "    Parameters:\n",
    "    - user_input: The message or query from the user.\n",
    "    - token: Authorization token from login.\n",
    "    - session_id: (Optional) Session ID for maintaining conversation context.\n",
    "    Returns:\n",
    "    - Response from the chat API.\n",
    "    \"\"\"\n",
    "    chat_url = f\"{BASE_URL}/{model_id}/chat\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    payload = {\n",
    "        \"user_input\": user_input,\n",
    "        \"session_id\": session_id,\n",
    "        \"provider\": \"on-prem\"\n",
    "    }\n",
    "    response = requests.post(chat_url, json=payload, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Chat request failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'failed',\n",
       " 'message': 'There is already an account associated with this email.',\n",
       " 'data': {}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signup(\"david\", \"david@thirdai.com\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMDgzNmFmOGMtNWEyOS00NzA2LThjOWYtOTc5ZDVjOGQzOTFiIiwiZXhwIjoxNzI3OTAyNTQ3fQ.-HttT4HHNdbCLhj08IBcY_pzS7l-xtAkFlLjZPVlKBQ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = login(\"david@thirdai.com\", \"password\")\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = list_models(\"david\", token)[\"data\"]\n",
    "for data in model_data:\n",
    "    print(data[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('files', <_io.BufferedReader name='/home/david/du_faqs.pdf'>)]\n",
      "[('files', <_io.BufferedReader name='/home/david/du_faqs.pdf'>), ('file_info', (None, '{\"unsupervised_files\": [{\"path\": \"/home/david/du_faqs.pdf\", \"location\": \"local\"}], \"supervised_files\": [], \"test_files\": []}', 'application/json'))]\n",
      "Model training job submitted successfully.\n",
      "{'status': 'success', 'message': 'Successfully submitted the job', 'data': {'model_id': 'ae6ead83-ff0b-4899-b2d0-e15f0e1807b1', 'user_id': '0836af8c-5a29-4706-8c9f-979d5c8d391b'}}\n"
     ]
    }
   ],
   "source": [
    "model_id = create_retriever_model(\"david-test\", token, files=[\"/home/david/du_faqs.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress...\n",
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "output = await_train(\"david/david-test\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success', 'message': 'Successfully deleted the model.', 'data': {}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete_model(\"david/david-test\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployed successfully. Deployment ID: ae6ead83-ff0b-4899-b2d0-e15f0e1807b1\n"
     ]
    }
   ],
   "source": [
    "output = deploy_model(\"david/david-test\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment in progress...\n",
      "Deployment in progress...\n",
      "Deployment in progress...\n",
      "Deployment in progress...\n",
      "Deployment completed successfully.\n"
     ]
    }
   ],
   "source": [
    "output = await_deploy(\"david/david-test\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = query_retrieval_model(model_id, \"how to pay my bill\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_model_id = \"250a9631-9627-47c8-bbdc-30ada92ef5f9\"\n",
    "token_model_id = \"40070a21-b6f3-4607-9289-3f6218af9597\"\n",
    "sentiment_model_id = \"ac58ccaf-8031-433a-9ab5-db20af83b978\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = login(\"admin@thirdai.com\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 9, 'text': \"mobile plans home internet & tv packages and much more! | du why have my monthly recurring charges increased? * if there is an increase in your monthly recurring charges it could be any of the following reasons: o you've upgraded your plan to another plan with a higher monthly recurring charge. o you've purchased additional recurring or one-time bundles on your plan such as data minutes roaming bundles etc. o you've purchased a new device with an instalment plan * please refer to the bill guide to understand more about each component in your monthly du bill.\", 'context': '', 'source': '/model_bazaar/models/250a9631-9627-47c8-bbdc-30ada92ef5f9/model.ndb/documents/3bbc2f6e-adaf-4d75-9e39-e5bba6b3f1b4/du_faqs.pdf', 'metadata': {'highlight': '{1: [12, 13, 14], 2: [0, 1, 2, 3, 4, 5, 6, 7]}', 'page': '1'}, 'source_id': '7f42a63a-2083-48da-b874-4a920938980d', 'score': 1.0522379875183105}, {'id': 64, 'text': 'you can register your gcc mastercard or visa credit card through: 1. du app (android and ios ) 2. my account 3. du shops du app * login to the du app and click on the settings icon on the top right corner * select \"payment card\" * update your card details and save my account * click on \"payments\" * enter your card details and save mobile plans home internet & tv packages and much more!', 'context': '', 'source': '/model_bazaar/models/250a9631-9627-47c8-bbdc-30ada92ef5f9/model.ndb/documents/3bbc2f6e-adaf-4d75-9e39-e5bba6b3f1b4/du_faqs.pdf', 'metadata': {'highlight': '{19: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 20: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}', 'page': '19'}, 'source_id': '7f42a63a-2083-48da-b874-4a920938980d', 'score': 1.037456750869751}, {'id': 43, 'text': 'get live chat support (through app only) chat with a du customer service agent between 8 am to midnight everyday. my account profile create a my account profile where you can: -access all your accounts -change your username & password -view your primary contact number -view & edit your alternate contact number -view & edit your billing address & method -view your plan benefits -view & manage your contract renewals & device installment plans how can i check my outstanding bill? you can check your outstanding bill amount to be paid via: 1. du app - on the main page 2. my account - on the main dashboard 3. sms \"bill\" to 1233 mobile plans home internet & tv packages and much more! | du how can i check my unbilled usage?', 'context': '', 'source': '/model_bazaar/models/250a9631-9627-47c8-bbdc-30ada92ef5f9/model.ndb/documents/3bbc2f6e-adaf-4d75-9e39-e5bba6b3f1b4/du_faqs.pdf', 'metadata': {'highlight': '{15: [6, 7, 8, 9, 10], 16: [0, 1, 2, 3, 4]}', 'page': '15'}, 'source_id': '7f42a63a-2083-48da-b874-4a920938980d', 'score': 0.6783549189567566}, {'id': 68, 'text': 'mobile plans home internet & tv packages and much more! | du how can i get my refund? bank transfer - you can email us using your registered email with du at customer.care@du.ae with your local (uae) bank details mentioned below and the refund will be transferred to your account bank name iban number bank branch account name bank address cash refund - can be requested at our following du stores (maximum of aed 5000): dubai hills mall - dubai hamdan branch - abu dhabi city center - fujairah manar mall - ras al khaimah umm al quwain store - umm al quwain ajman city center - ajman mobile plans home internet & tv packages and much more! | du how do i set up auto payment?', 'context': '', 'source': '/model_bazaar/models/250a9631-9627-47c8-bbdc-30ada92ef5f9/model.ndb/documents/3bbc2f6e-adaf-4d75-9e39-e5bba6b3f1b4/du_faqs.pdf', 'metadata': {'highlight': '{20: [17], 21: [0, 1, 2]}', 'page': '20'}, 'source_id': '7f42a63a-2083-48da-b874-4a920938980d', 'score': 0.6331170797348022}, {'id': 54, 'text': \"mobile plans home internet & tv packages and much more! | du how can i check my free units? you can check your free units through: * du app * my account * sms - send 'rewards' to 1233 on the du app the units displayed are combined units. click on the arrow next to the free units to have a detailed view.\", 'context': '', 'source': '/model_bazaar/models/250a9631-9627-47c8-bbdc-30ada92ef5f9/model.ndb/documents/3bbc2f6e-adaf-4d75-9e39-e5bba6b3f1b4/du_faqs.pdf', 'metadata': {'highlight': '{17: [11, 12, 13], 18: [0, 1, 2, 3, 4, 5]}', 'page': '17'}, 'source_id': '7f42a63a-2083-48da-b874-4a920938980d', 'score': 0.551293134689331}]\n"
     ]
    }
   ],
   "source": [
    "results = query_retrieval_model(retrieval_model_id, \"how to upgrade ios version\", token)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_text': 'my name is david and my phone number is 9728172948', 'tokens': ['my', 'name', 'is', 'david', 'and', 'my', 'phone', 'number', 'is', '9728172948'], 'predicted_tags': [['O'], ['O'], ['O'], ['NAME'], ['O'], ['O'], ['O'], ['O'], ['O'], ['PHONENUMBER']]}\n"
     ]
    }
   ],
   "source": [
    "token_tags = token_classifier_predict(token_model_id, \"my name is david and my phone number is 9728172948\", token)\n",
    "\n",
    "print(token_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['negative', 0.9343262314796448],\n",
       " ['positive', 0.041376352310180664],\n",
       " ['neutral', 0.024297324940562248]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_result = query_sentiment_model(sentiment_model_id, \"I hate this movie\", token)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_text': 'my name is david and my phone number is 9728172948', 'tokens': ['my', 'name', 'is', 'david', 'and', 'my', 'phone', 'number', 'is', '9728172948'], 'predicted_tags': [['O'], ['O'], ['O'], ['NAME'], ['O'], ['O'], ['O'], ['O'], ['O'], ['PHONENUMBER']]}\n",
      "[['negative', 0.9343262314796448], ['positive', 0.041376352310180664], ['neutral', 0.024297324940562248]]\n"
     ]
    }
   ],
   "source": [
    "token = login(\"admin@thirdai.com\", \"password\")\n",
    "\n",
    "results = query_retrieval_model(retrieval_model_id, \"how to upgrade ios version\", token)\n",
    "\n",
    "# results is a list of dictioaries with references\n",
    "# results[0].keys()\n",
    "# dict_keys(['id', 'text', 'context', 'source', 'metadata', 'source_id', 'score'])\n",
    "\n",
    "token_tags = token_classifier_predict(token_model_id, \"my name is david and my phone number is 9728172948\", token)\n",
    "# {'query_text': 'my name is david and my phone number is 9728172948', 'tokens': ['my', 'name', 'is', 'david', 'and', 'my', 'phone', 'number', 'is', '9729991112'], 'predicted_tags': [['O'], ['O'], ['O'], ['NAME'], ['O'], ['O'], ['O'], ['O'], ['O'], ['PHONENUMBER']]} \n",
    "print(token_tags)\n",
    "\n",
    "sentiment_result = query_sentiment_model(sentiment_model_id, \"I hate this movie\", token)\n",
    "\n",
    "print(sentiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"how to pay my bill\",\n",
    "    \"can I recharge for a friend\",\n",
    "    \"can I recharge for a friend on the website instead of du app\",\n",
    "    \"how to get refunds when I unsubscribe\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Sensitive Tokens Detected.\n",
      "Sentiment result is neutral\n",
      "Chat Response: {'status': 'success', 'message': 'Successful', 'data': {'response': \"I'm ready! Please provide me with the user's questions and I'll do my best to answer them.\"}}\n",
      "No Sensitive Tokens Detected.\n",
      "Sentiment result is neutral\n",
      "Chat Response: {'status': 'success', 'message': 'Successful', 'data': {'response': \"To pay your bill, you can use the following methods:\\n\\n1. Quick pay: Quick and fast way to do the payment without the need to login by using your credit/debit card and international American Express credit cards.\\n\\n2. Quick pay machines located in most malls and du stores\\n\\n3. 4200 N. payment self service kiosks installed across all of the UAE to pay all your postpaid and fixed bills using cash or international/uae credit/debit card (American Express/visa/master/jcb)\\n\\n4. Other channels: You can make your payments through exchange houses, Al Ansa, Fardan, Redha, Al Ansari, Al Razouki, International Exchange, Redha Al Ansari, Wall Street, Al Fardan Exchange, Al Razouki Exchange, Redha Al Fardan Exchange, Al Ansa Exchange\\n\\n5. International prepaid bundles: Click on your plan to 'buy bundle' and pay your bills using your bank card or Apple Pay via the Du app.\"}}\n"
     ]
    }
   ],
   "source": [
    "token = login(\"admin@thirdai.com\", \"password\")\n",
    "\n",
    "sentiment_map = {\"0\": \"negative\", \"1\": \"neutral\", \"2\": \"positive\"}\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter your query: \")\n",
    "    token_tags_result = token_classifier_predict(token_model_id, user_input, token)\n",
    "    tokens = token_tags_result['tokens']\n",
    "    predicted_tags = token_tags_result['predicted_tags']\n",
    "    sensitive_tokens = [tokens[i] for i in range(len(tokens)) if predicted_tags[i][0] != \"O\"]\n",
    "    if sensitive_tokens:\n",
    "        print(\"Sensitive Tokens Detected: \", sensitive_tokens, flush=True)\n",
    "    else:\n",
    "        print(\"No Sensitive Tokens Detected.\", flush=True)\n",
    "    sentiment_result = query_sentiment_model(sentiment_model_id, user_input, token)\n",
    "    # print(sentiment_result, flush=True)\n",
    "    if sentiment_result[0][1] > 0.7 or sentiment_result[2][1] > 0.7:\n",
    "        if sentiment_result[0][1] > sentiment_result[2][1]:\n",
    "            print(f\"Sentiment result is negative\")\n",
    "        else:\n",
    "            print(f\"Sentiment result is positive\")\n",
    "    else:\n",
    "        print(f\"Sentiment result is neutral\")\n",
    "    # retrieval_results = query_retrieval_model(retrieval_model_id, user_input, token)\n",
    "    # reference_text = \"\\n\".join([result['text'] for result in retrieval_results])\n",
    "    # print(\"Reference Text:\\n\", reference_text)\n",
    "    # prompt = f\"\"\n",
    "    response = chat(retrieval_model_id, user_input, token, session_id)\n",
    "    print(\"Chat Response:\", response, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
